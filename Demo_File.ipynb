{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Demo_File.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97siLeYd71QT",
        "colab_type": "text"
      },
      "source": [
        "##Setting up Keras & Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSK7sAOBnSRa",
        "colab_type": "code",
        "outputId": "5b534019-74a0-4e6b-f688-1e4525943f1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "pip install keras==1.2.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==1.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/3e/9926ce5c678b7a7978724a2ecf24857d89a415d152b8d3443e6d45c228b2/Keras-1.2.2.tar.gz (175kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: theano in /usr/local/lib/python3.6/dist-packages (from keras==1.2.2) (1.0.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==1.2.2) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from keras==1.2.2) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from theano->keras==1.2.2) (1.16.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from theano->keras==1.2.2) (1.3.0)\n",
            "Building wheels for collected packages: keras\n",
            "  Building wheel for keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/07/cf/b32db0a8d243b2fd6759d5d7cb650aa20670b2b740209cbf7e\n",
            "Successfully built keras\n",
            "\u001b[31mERROR: textgenrnn 1.4.1 has requirement keras>=2.1.5, but you'll have keras 1.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kapre 0.1.3.1 has requirement keras>=2.0.0, but you'll have keras 1.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fancyimpute 0.4.3 has requirement keras>=2.0.0, but you'll have keras 1.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.2.4\n",
            "    Uninstalling Keras-2.2.4:\n",
            "      Successfully uninstalled Keras-2.2.4\n",
            "Successfully installed keras-1.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLLilWmwZlyX",
        "colab_type": "code",
        "outputId": "7e2a3187-ad76-4127-c76c-41a28cc95ba0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize #For word tokenization\n",
        "from nltk.corpus import stopwords # For removing stop words\n",
        "from nltk.stem import WordNetLemmatizer # For Lemmentizing\n",
        "#from spellchecker import SpellChecker  # For Spell Correction\n",
        "from nltk.corpus import wordnet\n",
        "import spacy\n",
        "import string\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.applications.vgg16 import VGG16\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import model_from_json\n",
        "from string import punctuation\n",
        "\n",
        "\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import os\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.image import img_to_array\n",
        "import cv2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7ZoVMtVaAsC",
        "colab_type": "code",
        "outputId": "9e95cd08-fe05-4769-8a63-2913ec1f5c1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UtqT1vIZo0q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_preprocess(question):\n",
        "  #Converting it into Lower String\n",
        "  question = question.lower()\n",
        "  \n",
        "  #Removing punctuations\n",
        "  question = ''.join(c for c in question if c not in punctuation)\n",
        "  \n",
        "  #Removing Stop words\n",
        "  #stop_words = set(stopwords.words('english'))\n",
        "  #question =  \" \".join(x for x in question.split() if x not in stop_words)\n",
        "  \n",
        "  return question\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rT_kv81AZ49H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Tokenize(question):\n",
        "  t = Tokenizer()\n",
        "  t.fit_on_texts(question)\n",
        "  vocab_size = len(t.word_index) + 1\n",
        "  # integer encode the documents\n",
        "  question = t.texts_to_sequences(question)\n",
        "  return question"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSkAb4lYoFFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def padding(token):\n",
        "  from keras.preprocessing.sequence import pad_sequences as keras_pad_sequences\n",
        "  token = pad_sequences(token,maxlen=26,padding = \"pre\",truncating=\"post\",value = 0)\n",
        "  return token"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TO5OexObYQy",
        "colab_type": "code",
        "outputId": "f18fe0b3-9d21-434a-a231-8e1a6f99cf38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "VGG_model = VGG16(weights='imagenet',\n",
        "                  include_top=True,\n",
        "                  input_shape=(224,224,3))\n",
        "VGG_model.layers.pop()\n",
        "VGG_model.layers.pop()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0730 18:05:06.282252 139915517380480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:321: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0730 18:05:06.337085 139915517380480 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:634: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0730 18:05:06.354675 139915517380480 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:491: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0730 18:05:06.401358 139915517380480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2866: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0730 18:05:06.730881 139915517380480 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1047: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0730 18:05:19.849356 139915517380480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:112: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0730 18:05:19.852140 139915517380480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:117: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0730 18:05:19.853290 139915517380480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:122: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0730 18:05:19.881663 139915517380480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:269: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.Dense at 0x7f3ffbe46dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPj0VP2EcTps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models\n",
        "\n",
        "# Extracts the outputs of the top 8 layers:\n",
        "for layer in VGG_model.layers[:17]:\n",
        "  layer.trainable = False\n",
        "  #print(layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB49olYYbU0d",
        "colab_type": "code",
        "outputId": "96167ee1-8c41-40fc-ef36-4dbe61d9ac20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive/')\n",
        "base_model = load_model('/gdrive/My Drive/Colab Notebooks/VQA_DATASET/VQA_FINAL_model.h5')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0730 18:06:02.219774 139915517380480 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1029: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "W0730 18:06:03.645926 139915517380480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:658: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0730 18:06:03.798735 139915517380480 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmrpcFwlmNtr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def img_pre(imag):\n",
        "  image = img_to_array(imag)\n",
        "  img_resized=cv2.resize(image, (224,224), interpolation = cv2.INTER_AREA)\n",
        "  image = img_resized.reshape((1,img_resized.shape[0], img_resized.shape[1], img_resized.shape[2]))\n",
        "  return image\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B880F7OmbWQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testing(img,ques):\n",
        "  word=word_preprocess(ques)\n",
        "  token=Tokenize(word)\n",
        "  pad = padding(token)\n",
        "  image=img_pre(img)\n",
        "  \n",
        "  features = VGG_model.predict(image)\n",
        "  ans=base_model.predict([features,pad])\n",
        "  return ans\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0BG-lrbeZec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#x='/gdrive/My Drive/Colab Notebooks/VQA_DATASET/VQA DATA SET/Train_dataset_1/'\n",
        "x='/gdrive/My Drive/apple.jpg'\n",
        "imag=cv2.imread(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uorc7enMYto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_output = testing(imag,'what is the colour ?')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqE35GWEpQww",
        "colab_type": "code",
        "outputId": "c7a8c4ad-a5c5-4136-e9b8-e08ddee51990",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import joblib\n",
        "labelencoder = joblib.load('/gdrive/My Drive/Colab Notebooks/VQA_DATASET/labelencode_train.pkl')\n",
        "x=np.argsort(y_output)[0,-5:]\n",
        "lab=labelencoder.inverse_transform(x)\n",
        "for i,j in zip(x[::-1],lab[::-1]):\n",
        "  print(str(y_output[0,i]*100).zfill(5), \"% \", j)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50.21340847015381 %  cooking\n",
            "32.75773227214813 %  square\n",
            "5.563248321413994 %  samuel adams\n",
            "3.3321842551231384 %  kitchen\n",
            "1.9850263372063637 %  mirror\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}